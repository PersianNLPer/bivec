[lmthang@rescomp-13-276625:~/bivec ] $ ./demo-word.sh 
rm -rf bivec word2phrase distance word-analogy compute-accuracy runCLDC
gcc bivec.c -o bivec -lm -pthread -march=native -Wall -funroll-loops -Ofast -Wno-unused-result 
gcc word2phrase.c -o word2phrase -lm -pthread -march=native -Wall -funroll-loops -Ofast -Wno-unused-result 
gcc distance.c -o distance -lm -pthread -march=native -Wall -funroll-loops -Ofast -Wno-unused-result 
gcc word-analogy.c -o word-analogy -lm -pthread -march=native -Wall -funroll-loops -Ofast -Wno-unused-result 
gcc compute-accuracy.c -o compute-accuracy -lm -pthread -march=native -Wall -funroll-loops -Ofast -Wno-unused-result 
chmod +x *.sh
gcc runCLDC.c -o runCLDC -lm -pthread -march=native -Wall -funroll-loops -Ofast -Wno-unused-result 
time ./bivec -src-train data/data.10k.en -src-lang en -output vectors.bin -cbow 0 -size 200 -window 5 -negative 0 -hs 1 -sample 1e-3 -threads 1 -binary 0 -eval 0
Starting training using file data/data.10k.en
Vocab size: 3640
Words in train file: 280223
# Init hierarchical softmax syn1: 3640 x 200
# Start iter 0, num_threads=1
Alpha: 0.001762  Progress: 96.53%  Words/thread/sec: 200.08k  
# eval 0 en wordSim wordsim353 13.03 MC -10.82 RG -7.53 scws_nodup 6.87 morphoWordSim_new 15.40

syn0: min=-0.756787, max=0.682681, avg=0.000175
syn1: min=-2.440299, max=2.341284, avg=0.000030

real  0m10.116s
user  0m9.750s
sys 0m0.376s
